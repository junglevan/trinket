通讯的数学原理:
[信源]--消息-->[发送器]---信号-- []--接受到的信号-->[接收器]--消息-->[信宿]
                        [噪声源]_|

信号包含:连续的模拟信号,离散的数字信号(连续抽样也是连续,2psk信号传递相位,是离散的)
(程序员层面只考虑到数字信号,离散消息)

离散消息信息量:
I=-log2(P(x)) bit,  P(x)代表X事件发生的概率, P(x)=1时,I=0
理解:以二进制的数字枚举一类事件可能出现的独立(互斥)等概结果n种,任意X事件发生的概率P(x)=1/n

描述次事件需要征用log(n) bit,即-log(P(x)) bit

假设P(x1)+P(x2)+...P(xn)=1,x1~xn是一组可能出现的独立的结果n种
则平均信息量即信息熵为
       n
H = -  ∑  * P(xi)*log2(P(xi))
      i=1

当P(xi)=1/n时,平均信息量最大,即每个结果等概,平均不确定性最大
即Hmax = log2(n)

码元传输速率为:
RB = 1/T Baud; 每秒传递的结果数(码元数),T表示时间(s)
信息传输速率为:
Rb = H/T = H * RB bit/s(bps); 每秒传递的平均信息量

频带利用率:
Rb/B or RB/B; B表示信道传输所需要的带宽(Hz),一般和RB相匹配
e.g.保持Rb不变, 提高n即可能的结果数量,则Hmax会提高,所以为保持每秒传递Hmax不变,则T要提升,相应RB减少,B相应也可以减少,频带利用率Rb/B提升;
类比可能夺冠的选手越多,实力越平均,结果的平均信息量会高,主持人为了保持输出信息的效率一致,延长时间呼应悬念,一个消息的传递效率变低了,主持人的输出频率要求也可以放低,而在此低功率下的信息量依旧不变,主持人就能做到低配高能


